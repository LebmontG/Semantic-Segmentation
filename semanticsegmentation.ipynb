{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os,sys,gc\nimport cv2\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nimport functools\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-08-10T03:48:14.183853Z","iopub.execute_input":"2022-08-10T03:48:14.184216Z","iopub.status.idle":"2022-08-10T03:48:14.190391Z","shell.execute_reply.started":"2022-08-10T03:48:14.184185Z","shell.execute_reply":"2022-08-10T03:48:14.189102Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class EN(nn.Module):\n    def __init__(self,width_coeff,\n                 depth_div=8,min_depth=None,\n                 dropout_rate=0.2,drop_connect_rate=0.2,\n                 num_classes=1000):\n        super().__init__()\n        self.drop_connect_rate=drop_connect_rate\n        min_depth=min_depth or depth_div\n        depth_coeff=width_coeff\n        def upd_chnl(x):\n            if not width_coeff:return x\n            x *= width_coeff\n            new_x=max(min_depth,int(x+depth_div/2)//depth_div*depth_div)\n            if new_x < 0.9 * x:new_x+=depth_div\n            return int(new_x)\n        def upd_depth(x):\n            return int(math.ceil(x*depth_coeff))\n        self.stem=nn.Sequential(\n            CSP(3,upd_chnl(32),stride=2,kernel_size=3),\n            nn.BatchNorm2d(upd_chnl(32),eps=1e-3,momentum=0.01),\n            Swish())\n        self.blocks=nn.Sequential(\n            MBBlock(upd_chnl(32),upd_chnl(16),1,3,1,upd_depth(1),True,0.25,drop_connect_rate),\n            MBBlock(upd_chnl(16),upd_chnl(24),6,3,2,upd_depth(2),True,0.25,drop_connect_rate),\n            MBBlock(upd_chnl(24),upd_chnl(40),6,5,2,upd_depth(2),True,0.25,drop_connect_rate),\n            MBBlock(upd_chnl(40),upd_chnl(80),6,3,2,upd_depth(3),True,0.25,drop_connect_rate),\n            MBBlock(upd_chnl(80),upd_chnl(112),6,5,1,upd_depth(3),True,0.25,drop_connect_rate),\n            MBBlock(upd_chnl(112),upd_chnl(192),6,5,2,upd_depth(4),True,0.25,drop_connect_rate),\n            MBBlock(upd_chnl(192),upd_chnl(320),6,3,1,upd_depth(1),True,0.25,drop_connect_rate)\n        )\n        self.pooling=PSP(2,2)\n        return\n    def forward(self,x):\n        x=self.stem(x)\n        feature_maps=[]\n        last_x=None\n        for idx, block in enumerate(self.blocks):\n            x=block(x)\n            if idx in [3,5]:x=self.pooling(x)\n            if block.layers[0].dwc.depthwise.stride == [2, 2]:\n                feature_maps.append(last_x)\n            else:\n                feature_maps.append(x)\n            last_x=x\n        return feature_maps[1:]\n    def forward_(self,inputs):\n        return self.head(self.blocks(self.stem(inputs)))\n\n# BiFPN\nclass BiFPN(nn.Module):\n    def __init__(self,num_channels,conv_channels,\n                 if_first=False,attention=True):\n        \"\"\"\n        num_channels:number of channels\n        attention: if attention\n        conv_channels:numbers of convolution channels\n        if_first: whether the input comes directly from the efficientnet\n        \"\"\"\n        super(BiFPN,self).__init__()\n        self.epsilon =1e-4\n        for i in range(3,7):\n            # convolution\n            exec(\"self.conv\"+str(i)+\"_up=DSCB(num_channels)\")\n            exec(\"self.conv\"+str(i+1)+\"_down=DSCB(num_channels)\")\n            # feature scaling\n            exec(\"self.p\"+str(i)+\"_upsample=nn.Upsample(scale_factor=2,mode='nearest')\")\n            exec(\"self.p\"+str(i+1)+\"_downsample=PSP(3,2)\")\n        self.swish=Swish()\n        self.if_first=if_first\n        if self.if_first:\n            self.p5_down_channel=nn.Sequential(\n                CSP(conv_channels[2],num_channels,1),\n                nn.BatchNorm2d(num_channels,momentum=0.01,eps=1e-3),)\n            self.p4_down_channel=nn.Sequential(\n                CSP(conv_channels[1],num_channels,1),\n                nn.BatchNorm2d(num_channels,momentum=0.01,eps=1e-3),)\n            self.p3_down_channel=nn.Sequential(\n                CSP(conv_channels[0],num_channels,1),\n                nn.BatchNorm2d(num_channels,momentum=0.01,eps=1e-3),)\n            self.p5_to_p6=nn.Sequential(\n                CSP(conv_channels[2],num_channels,1),\n                nn.BatchNorm2d(num_channels,momentum=0.01,eps=1e-3),\n                PSP(3,2))\n            self.p6_to_p7=nn.Sequential(PSP(3,2))\n            self.p4_down_channel_2=nn.Sequential(\n                CSP(conv_channels[1],num_channels,1),\n                nn.BatchNorm2d(num_channels,momentum=0.01,eps=1e-3))\n            self.p5_down_channel_2=nn.Sequential(\n                CSP(conv_channels[2],num_channels,1),\n                nn.BatchNorm2d(num_channels,momentum=0.01,eps=1e-3))\n        # weight initialization\n        for i in range(3,7):\n            exec(\"self.p\"+str(i)+\"_w1=nn.Parameter(torch.ones(2,dtype=torch.float32),requires_grad=True)\")\n            exec(\"self.p\"+str(i)+\"_w1_relu=nn.ReLU()\")\n            exec(\"self.p\"+str(i+1)+\"_w2=nn.Parameter(torch.ones(3,dtype=torch.float32),requires_grad=True)\")\n            exec(\"self.p\"+str(i+1)+\"_w2_relu=nn.ReLU()\")\n        self.p7_w2=nn.Parameter(torch.ones(2,dtype=torch.float32),requires_grad=True)\n        self.p7_w2_relu=nn.ReLU()\n        self.attention =attention\n    def forward(self,inputs):\n        if self.attention:\n            if self.if_first:\n                p3,p4,p5=inputs\n                p6_in=self.p5_to_p6(p5)\n                p7_in=self.p6_to_p7(p6_in)\n                p3_in=self.p3_down_channel(p3)\n                p4_in=self.p4_down_channel(p4)\n                p5_in=self.p5_down_channel(p5)\n            else:\n                p3_in,p4_in,p5_in,p6_in,p7_in=inputs\n            #for i in range(3,8):exec(\"print(p\"+str(i)+\"_in.shape)\")\n            # Weights for P6_0 and P7_0 to P6_1\n            p6_w1=self.p6_w1_relu(self.p6_w1)\n            weight=p6_w1 / (torch.sum(p6_w1,dim=0) + self.epsilon)\n            # Connections for P6_0 and P7_0 to P6_1 respectively\n            t1,t2=assim(p6_in,self.p6_upsample(p7_in))\n            p6_up=self.conv6_up(self.swish(weight[0] *t1 + weight[1] *t2))\n            # Weights for P5_0 and P6_1 to P5_1\n            p5_w1=self.p5_w1_relu(self.p5_w1)\n            weight=p5_w1 / (torch.sum(p5_w1,dim=0) + self.epsilon)\n            # Connections for P5_0 and P6_1 to P5_1 respectively\n            t1,t2=assim(p5_in,self.p5_upsample(p6_up))\n            p5_up=self.conv5_up(self.swish(weight[0] *t1 + weight[1] *t2))\n            # Weights for P4_0 and P5_1 to P4_1\n            p4_w1=self.p4_w1_relu(self.p4_w1)\n            weight=p4_w1 / (torch.sum(p4_w1,dim=0) + self.epsilon)\n            # Connections for P4_0 and P5_1 to P4_1 respectively\n            #print(p4_in.shape,self.p4_upsample(p5_up).shape,p5_up.shape)\n            t1,t2=assim(p4_in,self.p4_upsample(p5_up))\n            #print(t1.shape,t2.shape)\n            p4_up=self.conv4_up(self.swish(weight[0] *t1 + weight[1] *t2))\n            # Weights for P3_0 and P4_1 to P3_2\n            p3_w1=self.p3_w1_relu(self.p3_w1)\n            weight=p3_w1 / (torch.sum(p3_w1,dim=0) + self.epsilon)\n            # Connections for P3_0 and P4_1 to P3_2 respectively\n            t1,t2=assim(p3_in, self.p3_upsample(p4_up))\n            p3_out=self.conv3_up(self.swish(weight[0] *t1 + weight[1] *t2))\n            if self.if_first:\n                p4_in=self.p4_down_channel_2(p4)\n                p5_in=self.p5_down_channel_2(p5)\n            # Weights for P4_0,P4_1 and P3_2 to P4_2\n            p4_w2=self.p4_w2_relu(self.p4_w2)\n            weight=p4_w2 / (torch.sum(p4_w2,dim=0) + self.epsilon)\n            # Connections for P4_0,P4_1 and P3_2 to P4_2 respectively\n            #print(p4_in.shape,p4_up.shape,self.p4_downsample(p3_out).shape)\n            t2,t3=assim(p4_in,self.p4_downsample(p3_out))\n            t1,t3=assim(p4_up,t3)\n            p4_out=self.conv4_down(\n                self.swish(weight[0] *t2 + weight[1] * t1 + weight[2] *t3))\n            # Weights for P5_0,P5_1 and P4_2 to P5_2\n            p5_w2=self.p5_w2_relu(self.p5_w2)\n            weight=p5_w2 / (torch.sum(p5_w2,dim=0) + self.epsilon)\n            # Connections for P5_0,P5_1 and P4_2 to P5_2 respectively\n            t2,t3=assim(p5_in, self.p5_downsample(p4_out))\n            t1,t3=assim(p5_up,t3)\n            p5_out=self.conv5_down(\n                self.swish(weight[0] *t2 + weight[1] * t1+ weight[2] *t3))\n            # Weights for P6_0,P6_1 and P5_2 to P6_2\n            p6_w2=self.p6_w2_relu(self.p6_w2)\n            weight=p6_w2 / (torch.sum(p6_w2,dim=0) + self.epsilon)\n            # Connections for P6_0,P6_1 and P5_2 to P6_2 respectively\n            t2,t3=assim(p6_in, self.p6_downsample(p5_out))\n            t1,t3=assim(p6_up,t3)\n            p6_out=self.conv6_down(\n                self.swish(weight[0] *t2 + weight[1] *t1 + weight[2] *t3))\n            # Weights for P7_0 and P6_2 to P7_2\n            p7_w2=self.p7_w2_relu(self.p7_w2)\n            weight=p7_w2 / (torch.sum(p7_w2,dim=0) + self.epsilon)\n            # Connections for P7_0 and P6_2 to P7_2\n            p7_out=self.conv7_down(self.swish(weight[0] * p7_in + weight[1] * self.p7_downsample(p6_out)))\n            return p3_out,p4_out,p5_out,p6_out,p7_out\n        else:\n            if self.if_first:\n                p3,p4,p5=inputs\n                p6_in=self.p5_to_p6(p5)\n                p7_in=self.p6_to_p7(p6_in)\n                p3_in=self.p3_down_channel(p3)\n                p4_in=self.p4_down_channel(p4)\n                p5_in=self.p5_down_channel(p5)\n            else:\n                # P3_0,P4_0,P5_0,P6_0 and P7_0\n                p3_in,p4_in,p5_in,p6_in,p7_in=inputs\n                # P7_0 to P7_2\n            # Connections for P6_0 and P7_0 to P6_1 respectively\n            p6_up=self.conv6_up(self.swish(p6_in + self.p6_upsample(p7_in)))\n\n            # Connections for P5_0 and P6_1 to P5_1 respectively\n            p5_up=self.conv5_up(self.swish(p5_in + self.p5_upsample(p6_up)))\n\n            # Connections for P4_0 and P5_1 to P4_1 respectively\n            p4_up=self.conv4_up(self.swish(p4_in + self.p4_upsample(p5_up)))\n\n            # Connections for P3_0 and P4_1 to P3_2 respectively\n            p3_out=self.conv3_up(self.swish(p3_in + self.p3_upsample(p4_up)))\n\n            if self.if_first:\n                p4_in=self.p4_down_channel_2(p4)\n                p5_in=self.p5_down_channel_2(p5)\n            # Connections for P4_0,P4_1 and P3_2 to P4_2 respectively\n            p4_out=self.conv4_down(\n                self.swish(p4_in + p4_up + self.p4_downsample(p3_out)))\n\n            # Connections for P5_0,P5_1 and P4_2 to P5_2 respectively\n            p5_out=self.conv5_down(\n                self.swish(p5_in + p5_up + self.p5_downsample(p4_out)))\n\n            # Connections for P6_0,P6_1 and P5_2 to P6_2 respectively\n            p6_out=self.conv6_down(\n                self.swish(p6_in + p6_up + self.p6_downsample(p5_out)))\n\n                # Connections for P7_0 and P6_2 to P7_2\n            p7_out=self.conv7_down(self.swish(p7_in + self.p7_downsample(p6_out)))\n\n            return p3_out,p4_out,p5_out,p6_out,p7_out\n\n# Classificaiton\nclass Classifier(nn.Module):\n    def __init__(self, in_channels,num_classes, num_layers, pyramid_levels=5, onnx_export=False):\n        super(Classifier, self).__init__()\n        self.num_classes=num_classes\n        self.num_layers=num_layers\n        self.conv_list=nn.ModuleList(\n            [DSCB_(in_channels, in_channels) for i in range(num_layers)])\n        self.bn_list=nn.ModuleList(\n            [nn.ModuleList([nn.BatchNorm2d(in_channels, momentum=0.01, eps=1e-3) for i in range(num_layers)]) for j in\n             range(pyramid_levels)])\n        self.header =DSCB_(in_channels, num_classes)\n        self.swish=Swish()\n\n    def forward(self, inputs,shape):\n        feats=[]\n        for feat, bn_list in zip(inputs, self.bn_list):\n            for i, bn, conv in zip(range(self.num_layers), bn_list, self.conv_list):\n                feat=self.swish(bn(conv(feat)))\n            #print(feat.shape)\n            feat=F.interpolate(feat,shape)\n            feat=self.header(feat)\n            #feat=feat.permute(0, 2, 3, 1)\n            #feat=feat.contiguous().view(feat.shape[0], feat.shape[1], feat.shape[2],self.num_classes)\n            #feat=feat.contiguous().view(-1, self.num_classes)\n            feats.append(feat)\n        return sum(feats).sigmoid()\n\n# Class Semantic Segmentation\nclass SSNet(nn.Module):\n    def __init__(self,class_num=2,compound_coef=0):\n        super(SSNet, self).__init__()\n        self.compound_coef=compound_coef\n        self.class_num=class_num\n        self.backbone_compound_coef=[0, 1, 2, 3, 4, 5, 6, 6, 7]\n        self.fpn_num_filters=[64, 88, 112, 160, 224, 288, 384, 384, 384]\n        self.fpn_cell_repeats=[1, 4, 5, 6, 7, 7, 8, 8, 8]\n        self.input_sizes=[512, 640, 768, 896, 1024, 1280, 1280, 1536, 1536]\n        self.box_class_repeats=[3, 3, 3, 4, 4, 4, 5, 5, 5]\n        self.pyramid_levels=[5, 5, 5, 5, 5, 5, 5, 5, 6]\n        self.anchor_scale=[4., 4., 4., 4., 4., 4., 4., 5., 4.]\n        self.conv_channel_coef={\n            0: [40, 80, 112],\n            1: [40, 112, 320],\n            2: [48, 120, 352],\n            3: [48, 136, 384],\n            4: [56, 160, 448],\n            5: [64, 176, 512],\n            6: [72, 200, 576],\n            7: [72, 200, 576],\n            8: [80, 224, 640],}\n        self.BiFPN= nn.Sequential(\n            *[BiFPN(self.fpn_num_filters[self.compound_coef],\n                    self.conv_channel_coef[self.compound_coef],\n                    True if i == 0 else False,\n                    attention=True)\n              for i in range(self.fpn_cell_repeats[self.compound_coef])])\n        self.classifier=Classifier(in_channels=self.fpn_num_filters[self.compound_coef],\n                                     num_classes=self.class_num,\n                                     num_layers=self.box_class_repeats[self.compound_coef],\n                                     pyramid_levels=self.pyramid_levels[self.compound_coef])\n        self.efficient=EN(self.backbone_compound_coef[compound_coef])\n        return\n    def forward(self,x):\n        shape=x.shape[-2:]\n        x=self.efficient(x)\n        #for ele in x:print(ele.shape)\n        #x=[x[i] for i in [1,3,5]]\n        x=[x[i] for i in [1,2,3]]\n        x=self.BiFPN(x)\n        x=self.classifier(x,shape)\n        return x\n\n#Assimilate tensors\ndef assim(t1,t2):\n    shape=t1.shape[-2:]\n    t2=F.interpolate(t2,shape)\n    # shape=np.array(t1.shape)-np.array(t2.shape)\n    # if shape.sum()>0:t2=F.pad(t2,list(shape),\"constant\",0)\n    # elif shape.sum()<0:t1=F.pad(t1,list(-shape),\"constant\",0)\n    return t1,t2\n\n#Swish from Google\nclass Swish(nn.Module):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n\n#MaxPooling with Same Padding\nclass PSP(nn.Module):\n    def __init__(self, *args, **kwargs):\n        super().__init__()\n        self.pool = nn.MaxPool2d(*args, **kwargs)\n        self.stride = self.pool.stride\n        self.kernel_size = self.pool.kernel_size\n        #print(self.stride,self.pool);input()\n        if isinstance(self.stride, int):\n            self.stride = [self.stride]*2\n        if isinstance(self.kernel_size, int):\n            self.kernel_size = [self.kernel_size] * 2\n    def forward(self, x):\n        h,w=x.shape[-2:]\n        pad_w= (math.ceil(w / self.stride[1]) - 1) * self.stride[1] - w + self.kernel_size[1]\n        pad_h= (math.ceil(h / self.stride[0]) - 1) * self.stride[0] - h + self.kernel_size[0]\n        return self.pool(F.pad(x,[pad_w//2,pad_w-pad_w//2,pad_h//2,pad_h-pad_h//2]))\n\n#Convolution with Same Padding\nclass CSP(nn.Module):\n    def __init__(self, in_channels, out_channels,\n                 kernel_size, stride=1, bias=True,\n                 groups=1, dilation=1, **kwargs):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels,out_channels,\n                              kernel_size, stride=stride,\n                              bias=bias, groups=groups)\n        self.stride=self.conv.stride\n        self.kernel_size = self.conv.kernel_size\n        self.dilation = self.conv.dilation\n    def forward(self, x):\n        h,w=x.shape[-2:]\n        pad_w= (math.ceil(w / self.stride[1]) - 1) * self.stride[1] - w + self.kernel_size[1]\n        pad_h= (math.ceil(h / self.stride[0]) - 1) * self.stride[0] - h + self.kernel_size[0]\n        return self.conv(F.pad(x,[pad_w//2,pad_w-pad_w//2,pad_h//2,pad_h-pad_h//2]))\n\n#Depthwise Seperable Convolution Block\nclass DSCB(nn.Module):\n    def __init__(self, in_channels,out_channels=None):\n        \"\"\"\n        in_channels: number of input channels\n        out_channels: number of output channels\n        \"\"\"\n        super(DSCB, self).__init__()\n        if out_channels is None:out_channels = in_channels\n        # groups=in_channels\n        self.depthwise=CSP(in_channels, in_channels,kernel_size=3, stride=1, groups=in_channels, bias=False)\n        self.pointwise=CSP(in_channels, out_channels, kernel_size=1, stride=1)\n        self.bn = nn.BatchNorm2d(num_features=out_channels, momentum=0.01, eps=1e-3)\n    def forward(self, x):\n        x = self.pointwise(self.depthwise(x))\n        return self.bn(x)\nclass DSCB_(nn.Module):\n    def __init__(self, in_channels,out_channels=None):\n        \"\"\"\n        in_channels: number of input channels\n        out_channels: number of output channels\n        \"\"\"\n        super(DSCB_, self).__init__()\n        if out_channels is None:out_channels = in_channels\n        # groups=in_channels\n        self.depthwise=CSP(in_channels, in_channels,kernel_size=3, stride=1, groups=in_channels, bias=False)\n        self.pointwise=CSP(in_channels, out_channels, kernel_size=1, stride=1)\n        #self.bn = nn.BatchNorm2d(num_features=out_channels, momentum=0.01, eps=1e-3)\n    def forward(self, x):\n        return self.pointwise(self.depthwise(x))\n\n#Dynamic or static padding\ndef SP(image_size=None):\n    if image_size is None:return CDSP\n    else:\n        return functools.partial(CSP, image_size=image_size)\n\n#Dynamic Convolution with Same Padding\nclass CDSP(nn.Conv2d):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):\n        super().__init__(in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n        self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]] * 2\n    def forward(self, x):\n        ih, iw = x.size()[-2:]\n        kh, kw = self.weight.size()[-2:]\n        sh, sw = self.stride\n        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n        if pad_h > 0 or pad_w > 0:\n            x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2])\n        return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n\n#SEModule\nclass SEM(nn.Module):\n    def __init__(self, in_channels, squeeze_ch):\n        super().__init__()\n        self.se = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Conv2d(in_channels, squeeze_ch, kernel_size=1, stride=1, padding=0, bias=True),\n            Swish(),\n            nn.Conv2d(squeeze_ch,in_channels, kernel_size=1, stride=1, padding=0, bias=True),\n        )\n    def forward(self, x):\n        return x * torch.sigmoid(self.se(x))\n\n#MBconvolution layer\nclass MBConv(nn.Module):\n    def __init__(self,in_channels, out_channels,expand,\n                 kernel_size, stride,\n                 se_ratio, dc_ratio=0.2,resi=True):\n        super().__init__()\n        mid=in_channels*expand\n        self.expand=nn.Sequential(\n            CSP(in_channels,mid,kernel_size),\n            nn.BatchNorm2d(mid,eps=1e-3, momentum=0.01),\n            Swish())\n        self.dwc=DSCB(mid,mid)\n        self.se=SEM(mid, int(in_channels * se_ratio)) if se_ratio > 0 else nn.Identity()\n        self.proj=nn.Sequential(\n            CSP(mid,out_channels,kernel_size),\n            nn.BatchNorm2d(out_channels, 1e-3, 0.01))\n        self.resi=resi and (stride == 1) and (in_channels==out_channels)\n    def forward(self, inputs):\n        x = self.expand(inputs)\n        x = self.dwc(x)\n        x = self.proj(self.se(x))\n        if self.resi:\n            x = x + inputs\n        return x\n\n#MBconvolution Block\nclass MBBlock(nn.Module):\n    def __init__(self,in_channels, out_channels,\n                 expand, kernel, stride,\n                 num_repeat, skip, se_ratio,\n                 drop_connect_ratio=0.2):\n        super().__init__()\n        layers = [MBConv(in_channels, out_channels,\n                         expand, kernel,stride,\n                         skip, se_ratio,\n                         drop_connect_ratio)]\n        for i in range(1, num_repeat):\n            layers.append(MBConv(out_channels,out_channels, expand, kernel, 1, skip, se_ratio, drop_connect_ratio))\n        self.layers = nn.Sequential(*layers)\n    def forward(self, x):\n        return self.layers(x)\n\n# keep the batch shape\nclass flatten(nn.Module):\n    def forward(self, x):\n        return x.view(x.shape[0],-1)\n\n#MIoU\ndef mIoU(p1,p2):\n    if len(p1.shape)>2:\n        p1=torch.argmax(p1,1)[0]\n    p=p1+p2\n    #if unionsection<1:return 1\n    return ((p==2).sum()/(p>0).sum()).item()\n\n#Boundary\ndef Boundary(p):\n    if len(p.shape)>2:\n        p=torch.argmax(p,1)[0].cpu().numpy().astype('float64')\n    else:p=p.cpu().numpy()\n    #print(p.shape)\n    h,w=p.shape\n    dil=int(round(0.02*np.sqrt(h ** 2 + w ** 2)))\n    if dil<1:dil=1\n    p_=cv2.copyMakeBorder(p, 1, 1, 1, 1, cv2.BORDER_CONSTANT, value=0)\n    kernel=np.ones((3, 3), dtype=np.uint8)\n    p_erode=cv2.erode(p_,kernel,iterations=dil)\n    return torch.from_numpy(p-p_erode[1 : h + 1, 1 : w + 1])\n\n#Boundary mIoU\ndef BIoU(p1,p2):\n    p1,p2=Boundary(p1),Boundary(p2)\n    intersection=((p1+p2)==2).sum()\n    unionsection=(torch.logical_or(p1,p2)).sum()\n    if unionsection<1:return 1\n    return (intersection/unionsection).item()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-10T04:38:28.181666Z","iopub.execute_input":"2022-08-10T04:38:28.182054Z","iopub.status.idle":"2022-08-10T04:38:28.285321Z","shell.execute_reply.started":"2022-08-10T04:38:28.182021Z","shell.execute_reply":"2022-08-10T04:38:28.284189Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"labelpath=\"../input/weizmann-horse-database/weizmann_horse_db/mask/\"\ndatapath=\"../input/weizmann-horse-database/weizmann_horse_db/horse/\"\nprop=0.85\nclass_num=2\ncompound_coef=0\ndevice=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nnames=os.walk(labelpath)\nfor name in names:\n    names=name[-1]\n    break\nloc,l=1,len(names)\ntx,ty,vx,vy=[],[],[],[]\nfor name in names:\n    if loc<l*prop:\n        tmp=cv2.imread(labelpath+name)\n        tmp=np.mean(tmp,2)\n        ty.append(torch.tensor(tmp).contiguous().view(1,-1))\n        #ty.append(torch.tensor(tmp))\n        tmp=cv2.imread(datapath+name)\n        tx.append(torch.FloatTensor(tmp).unsqueeze(0).permute(0,3,1,2))\n    else:\n        tmp=cv2.imread(labelpath+name)\n        tmp=np.mean(tmp,2)\n        #vy.append(torch.tensor(tmp).contiguous().view(1,-1))\n        vy.append(torch.tensor(tmp))\n        tmp=cv2.imread(datapath+name)\n        vx.append(torch.FloatTensor(tmp).unsqueeze(0).permute(0,3,1,2))\n    loc+=1\n#tx,ty=np.array(tx),np.array(ty)\nind=np.random.permutation(np.arange(len(tx)))\ntx,ty=[tx[i] for i in ind],[ty[i] for i in ind]\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T04:04:30.083360Z","iopub.execute_input":"2022-08-10T04:04:30.083720Z","iopub.status.idle":"2022-08-10T04:04:36.810794Z","shell.execute_reply.started":"2022-08-10T04:04:30.083690Z","shell.execute_reply":"2022-08-10T04:04:36.809753Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"4051"},"metadata":{}}]},{"cell_type":"code","source":"model=SSNet(class_num,compound_coef).to(device)\n#model.load_state_dict(torch.load('../input/SSNet/m.pth'))\nmodel.load_state_dict(torch.load('m.pth'))\nloss=nn.CrossEntropyLoss()\nopt=optim.Adam(model.parameters())\nres=[]\nepisodes=5\nfor j in range(episodes):\n    for i in tqdm(range(len(tx))):\n        #if i<150:continue\n        image,label=tx[i],ty[i]\n        #torch.cuda.empty_cache()\n        image,label=image.to(device),label.to(device)\n        opt.zero_grad()\n        y=model(image)\n        y=y.permute(0, 2, 3, 1)\n        y=y.contiguous().view(-1,class_num)\n        l=loss(y,torch.tensor(label,dtype=torch.long)[0])\n        l.backward()\n        opt.step()\n    miou,biou=[],[]\n    with torch.no_grad():\n        for image,label in tqdm(zip(vx,vy)):\n            image,label=image.to(device),label.to(device)\n            y=model(image)\n            miou.append(mIoU(y,label))\n            biou.append(BIoU(y,label))\n    print(sum(miou)/50)\n    res.append(sum(miou)/50)\ntorch.save(model.state_dict(),'m.pth')\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working')\nprint(os.getcwd())\nprint(os.listdir(\"/kaggle/working\"))\nfrom IPython.display import FileLink\nFileLink('m.pth')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T05:38:19.596831Z","iopub.execute_input":"2022-08-10T05:38:19.597425Z","iopub.status.idle":"2022-08-10T05:38:19.606182Z","shell.execute_reply.started":"2022-08-10T05:38:19.597386Z","shell.execute_reply":"2022-08-10T05:38:19.605039Z"},"trusted":true},"execution_count":143,"outputs":[{"name":"stdout","text":"/kaggle/working\n['.virtual_documents', '__notebook_source__.ipynb', 'm.pth']\n","output_type":"stream"},{"execution_count":143,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/m.pth","text/html":"<a href='m.pth' target='_blank'>m.pth</a><br>"},"metadata":{}}]}]}